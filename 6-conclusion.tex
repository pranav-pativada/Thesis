\chapter{Conclusion}
\label{chap:conclusion}

In this chapter, we summarise the main contributions of this thesis, discuss its implications and suggest future work directions.

\section{Summary}

\section{Future Work}

\subsection{Hybrid Approaches}
\label{ssec:hybrid_approaches}

\subsection{Theoretical Rigour}
\label{sec:theoretical_rigour}

\section{Concluding Thoughts}
\label{sec:concluding_thoughts}

Optimisation in deep learning is a challenging problem, but it is fundamental for advancing the state-of-the-art. Optimisation has led to the development of powerful models, techniques and novel innovations. The work presented in this thesis is a step towards more efficient optimisation. We present KryBall, our second-order optimisation algorithm that combines the advantages of first and second-order methods by using Krylov subspaces, the Saddle-Free-Newton, and a trust-region framework. We thus take a step towards the goal of efficiently navigating the optimisation landscape, and improving the performance of integral machine learning models and tasks in today's world.